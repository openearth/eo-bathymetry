{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0df4bdc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vaklodingen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8ecafe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jarkus Grids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3959427c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ctypes import ArgumentError\n",
    "from datetime import date as Date\n",
    "from json import dumps\n",
    "from typing import Any, Dict, List, Optional, Tuple\n",
    "from re import sub\n",
    "\n",
    "import ee\n",
    "from eepackages.applications.bathymetry import Bathymetry\n",
    "from eepackages import tiler\n",
    "from googleapiclient.discovery import build\n",
    "\n",
    "#from eo_bathymetry_functions.utils import get_rolling_window_dates\n",
    "\n",
    "\n",
    "LEGACY_ASSET_PREFIX: str = \"projects/earthengine-legacy/assets\"\n",
    "\n",
    "def get_tile_bathymetry(tile: ee.Feature, start: ee.String, stop: ee.String) -> ee.Image:\n",
    "    \"\"\"\n",
    "    Get subtidal bathymetry based on tile geometry.\n",
    "    Server-side compliant for GEE.\n",
    "    args:\n",
    "        tile (ee.Feature): tile geometry used to obtain bathymetry.\n",
    "        start (ee.String): start date in YYYY-MM-dd format.\n",
    "        stop (ee.String): stop date in YYYY-MM-dd format.\n",
    "    \n",
    "    returns:\n",
    "        ee.Image: image containing subtidal bathymetry covering tile.\n",
    "    \"\"\"\n",
    "\n",
    "    bounds: ee.Geometry = ee.Feature(tile).geometry().bounds(1)\n",
    "    sdb: Bathymetry = Bathymetry()\n",
    "    zoom: ee.String = ee.String(tile.get(\"zoom\"))\n",
    "    tx: ee.String = ee.String(tile.get(\"tx\"))\n",
    "    ty: ee.String = ee.String(tile.get(\"ty\"))\n",
    "    tile_name: ee.String = ee.String(\"z\").cat(zoom).cat(\"_x\").cat(tx).cat(\"_y\").cat(ty).replace(\"\\.\\d+\", \"\", \"g\")\n",
    "    img_fullname: ee.String = ee.String(tile_name).cat(\"_t\").cat(ee.Date(start).millis().format())\n",
    "    \n",
    "    image: ee.Image = sdb.compute_inverse_depth(\n",
    "                bounds=bounds,\n",
    "                start=start,\n",
    "                stop=stop,\n",
    "                filter_masked=True,\n",
    "                scale=tiler.zoom_to_scale(ee.Number.parse(tile.get(\"zoom\"))).multiply(5),\n",
    "    )\n",
    "    image = image.set(\n",
    "        \"fullname\", img_fullname,\n",
    "        \"system:time_start\", ee.Date(start).millis(),\n",
    "        \"system:time_stop\", ee.Date(stop).millis(),\n",
    "        \"zoom\", zoom,\n",
    "        \"tx\", tx,\n",
    "        \"ty\", ty\n",
    "    )\n",
    "    return image\n",
    "\n",
    "def asset_to_tile( # TO BE MODIFIED!\n",
    "    image: ee.Image,\n",
    "    tile: ee.Feature,\n",
    "    export_scale: int,\n",
    "    asset_path_prefix: str,\n",
    "    asset_name: str,\n",
    "    overwrite: bool,\n",
    "    global_log_fields: Optional[Dict[str, str]] = None\n",
    ") -> Optional[ee.batch.Task]:\n",
    "    \"\"\"\n",
    "    Export a tile to a earth engine asset\n",
    "    args:\n",
    "        image (ee.Image): image to export\n",
    "        tile (ee.Feature): tile that defines geometry\n",
    "        export_scale (int): scale for the tile export\n",
    "        asset_path_prefix (str): prefix of the asset path\n",
    "        asset_name (str): name of the asset\n",
    "        overwrite (bool): whether to overwrite any existing artifacts\n",
    "        global_log_fields (Optional(Dict)): log fields for the entire cloud function.\n",
    "    returns:\n",
    "        Optional[ee.batch.Task] started task\n",
    "    \"\"\"\n",
    "    if not global_log_fields:\n",
    "        global_log_fields: Dict[str, str] = {}\n",
    "    asset_id: str = f\"{asset_path_prefix}/{asset_name}\"\n",
    "    asset: Dict[str, Any] = ee.data.getInfo(f\"{LEGACY_ASSET_PREFIX}/{asset_id}\")\n",
    "    if overwrite and asset:\n",
    "        print(dumps({\n",
    "            \"severity\": \"NOTICE\",\n",
    "            \"message\": f\"deleting asset {asset_name}\",\n",
    "            **global_log_fields\n",
    "        }))\n",
    "        ee.data.deleteAsset(f\"{LEGACY_ASSET_PREFIX}/{asset_id}\")\n",
    "    elif asset:\n",
    "        print(dumps({\n",
    "            \"severity\": \"NOTICE\",\n",
    "            \"message\": f\"asset {asset} already exists, skipping {asset_name}\",\n",
    "            **global_log_fields\n",
    "        }))\n",
    "        return\n",
    "\n",
    "    bounds: ee.Geometry = tile.geometry().buffer(export_scale).bounds()\n",
    "    task: ee.batch.Task = ee.batch.Export.image.toAsset(\n",
    "        image,\n",
    "        assetId=asset_id,\n",
    "        description=asset_name,\n",
    "        region=bounds,\n",
    "        scale=export_scale,\n",
    "        crs=\"EPSG:3857\",\n",
    "        maxPixels=1e10\n",
    "    )\n",
    "    task.start()\n",
    "    print(dumps({\n",
    "        \"severity\": \"NOTICE\",\n",
    "        \"message\": f\"exporting {asset_name} to {asset_id}, taskid: {task.id}\",\n",
    "        **global_log_fields\n",
    "    }))\n",
    "\n",
    "\n",
    "def tile_to_asset(\n",
    "    image: ee.Image,\n",
    "    tile: ee.Feature,\n",
    "    export_scale: int,\n",
    "    asset_path_prefix: str,\n",
    "    asset_name: str,\n",
    "    overwrite: bool,\n",
    "    global_log_fields: Optional[Dict[str, str]] = None\n",
    ") -> Optional[ee.batch.Task]:\n",
    "    \"\"\"\n",
    "    Export a tile to a earth engine asset\n",
    "    args:\n",
    "        image (ee.Image): image to export\n",
    "        tile (ee.Feature): tile that defines geometry\n",
    "        export_scale (int): scale for the tile export\n",
    "        asset_path_prefix (str): prefix of the asset path\n",
    "        asset_name (str): name of the asset\n",
    "        overwrite (bool): whether to overwrite any existing artifacts\n",
    "        global_log_fields (Optional(Dict)): log fields for the entire cloud function.\n",
    "    returns:\n",
    "        Optional[ee.batch.Task] started task\n",
    "    \"\"\"\n",
    "    if not global_log_fields:\n",
    "        global_log_fields: Dict[str, str] = {}\n",
    "    asset_id: str = f\"{asset_path_prefix}/{asset_name}\"\n",
    "    asset: Dict[str, Any] = ee.data.getInfo(f\"{LEGACY_ASSET_PREFIX}/{asset_id}\")\n",
    "    if overwrite and asset:\n",
    "        print(dumps({\n",
    "            \"severity\": \"NOTICE\",\n",
    "            \"message\": f\"deleting asset {asset_name}\",\n",
    "            **global_log_fields\n",
    "        }))\n",
    "        ee.data.deleteAsset(f\"{LEGACY_ASSET_PREFIX}/{asset_id}\")\n",
    "    elif asset:\n",
    "        print(dumps({\n",
    "            \"severity\": \"NOTICE\",\n",
    "            \"message\": f\"asset {asset} already exists, skipping {asset_name}\",\n",
    "            **global_log_fields\n",
    "        }))\n",
    "        return\n",
    "\n",
    "    bounds: ee.Geometry = tile.geometry().buffer(export_scale).bounds()\n",
    "    task: ee.batch.Task = ee.batch.Export.image.toAsset(\n",
    "        image,\n",
    "        assetId=asset_id,\n",
    "        description=asset_name,\n",
    "        region=bounds,\n",
    "        scale=export_scale,\n",
    "        crs=\"EPSG:3857\",\n",
    "        maxPixels=1e10\n",
    "    )\n",
    "    task.start()\n",
    "    print(dumps({\n",
    "        \"severity\": \"NOTICE\",\n",
    "        \"message\": f\"exporting {asset_name} to {asset_id}, taskid: {task.id}\",\n",
    "        **global_log_fields\n",
    "    }))\n",
    "\n",
    "def tile_to_cloud_storage(\n",
    "    image: ee.Image,\n",
    "    tile: ee.Feature,\n",
    "    export_scale: int,\n",
    "    bucket: str,\n",
    "    bucket_path: str,\n",
    "    overwrite: bool,\n",
    "    global_log_fields: Optional[Dict[str, str]] = None\n",
    ") -> Optional[ee.batch.Task]:\n",
    "    \"\"\"\n",
    "    Export a tile to cloud storage\n",
    "    args:\n",
    "        image (ee.Image): image to export\n",
    "        tile (ee.Feature): tile that defines geometry\n",
    "        export_scale (int): scale for the tile export\n",
    "        bucket (str): name of the gcs bucket\n",
    "        bucket_path (str): path to the object in the bucket\n",
    "        overwrite (bool): whether to overwrite any existing artifacts\n",
    "        global_log_fields (Optional(Dict)): log fields for the entire cloud function.\n",
    "    returns:\n",
    "        Optional[ee.batch.Task] started task\n",
    "    \"\"\"\n",
    "    if not global_log_fields:\n",
    "        global_log_fields: Dict[str, str] = {}\n",
    "    with build('storage', 'v1') as storage:\n",
    "        res = storage.objects().list(bucket=bucket, prefix=\"/\".join(bucket_path.split(\"/\")[:-1])).execute()\n",
    "    if not overwrite:\n",
    "        try:\n",
    "            object_exists = any(map(lambda item: item.get(\"name\").startswith(bucket_path), res.get(\"items\")))\n",
    "        except (AttributeError, TypeError):\n",
    "            object_exists = False\n",
    "        if object_exists:\n",
    "            print(dumps({\n",
    "                \"severity\": \"NOTICE\",\n",
    "                \"message\": f\"object {bucket_path} already exists in bucket {bucket}, skipping\",\n",
    "                **global_log_fields\n",
    "            }))\n",
    "            return\n",
    "    \n",
    "    bounds: ee.Geometry = tile.geometry().buffer(export_scale).bounds()\n",
    "        \n",
    "    task: ee.batch.Task = ee.batch.Export.image.toCloudStorage(\n",
    "        image,\n",
    "        bucket=bucket,\n",
    "        description=bucket_path.replace(\"/\", \"_\"),\n",
    "        fileNamePrefix=bucket_path,\n",
    "        region=bounds,\n",
    "        scale=export_scale,\n",
    "        crs=\"EPSG:3857\",\n",
    "        maxPixels=1e10\n",
    "    )\n",
    "    task.start()\n",
    "    print(dumps({\n",
    "        \"severity\": \"NOTICE\",\n",
    "        \"message\": f\"exporting tile to bucket {bucket}/{bucket_path}, taskid: {task.id}\",\n",
    "        **global_log_fields\n",
    "    }))\n",
    "    return task\n",
    "\n",
    "def export_sdb_tiles(\n",
    "    sink: str,\n",
    "    tile_list: ee.List,\n",
    "    num_tiles: int,\n",
    "    export_scale: int,\n",
    "    sdb_tiles: ee.ImageCollection,\n",
    "    name_suffix: str,\n",
    "    task_list: List[ee.batch.Task],\n",
    "    overwrite: bool,\n",
    "    bucket: Optional[str] = None,\n",
    "    asset_path: Optional[str] = None,\n",
    "    global_log_fields: Optional[Dict[str, str]] = None\n",
    ") -> List[ee.batch.Task]:\n",
    "    \"\"\"\n",
    "    Export list of tiled images containing subtidal bathymetry. Fires off the tasks and adds to the list of tasks.\n",
    "    based on: https://github.com/gee-community/gee_tools/blob/master/geetools/batch/imagecollection.py#L166\n",
    "    args:\n",
    "        sink (str): type of data sink to export to. Viable options are: \"asset\" and \"cloud\".\n",
    "        tile_list (ee.List): list of tile features.\n",
    "        num_tiles (int): number of tiles in `tile_list`.\n",
    "        export_scale (int): scale of the export product.\n",
    "        sdb_tiles (ee.ImageCollection): collection of subtidal bathymetry images corresponding\n",
    "            to input tiles.\n",
    "        name_suffix (str): unique identifier after tile statistics.\n",
    "        task_list (List[ee.batch.Task]): list of tasks, adds tasks created to this list.\n",
    "        overwrite (bool): whether to overwrite the current assets under the same `asset_path`.\n",
    "        bucket (Optional(str)): Bucket where the data is stored. Only used when sink = \"cloud\".\n",
    "        asset_path (Optional(str)): Path where the asset will be stored. Only used when sink = \"asset\".\n",
    "        global_log_fields (Optional(Dict)): log fields for the entire cloud function.\n",
    "    \n",
    "    returns:\n",
    "        List[ee.batch.Task]: list of started tasks\n",
    "    \"\"\"\n",
    "    if not global_log_fields:\n",
    "        global_log_fields: Dict[str, str] = {}\n",
    "    if sink == \"asset\":\n",
    "        # create folder if not exists\n",
    "        ee.data.create_assets(asset_ids=[asset_path], asset_type=\"Folder\", mk_parents=True)\n",
    "    \n",
    "    for i in range(num_tiles):\n",
    "        # get tile\n",
    "        temp_tile: ee.Feature = ee.Feature(tile_list.get(i))\n",
    "        tile_metadata: Dict[str, Any] = temp_tile.getInfo()[\"properties\"]\n",
    "        tx: str = tile_metadata[\"tx\"]\n",
    "        ty: str = tile_metadata[\"ty\"]\n",
    "        zoom: str = tile_metadata[\"zoom\"]\n",
    "        # filter imagecollection based on tile\n",
    "        filtered_ic: ee.ImageCollection = sdb_tiles \\\n",
    "            .filterMetadata(\"tx\", \"equals\", tx) \\\n",
    "            .filterMetadata(\"ty\", \"equals\", ty) \\\n",
    "            .filterMetadata(\"zoom\", \"equals\", zoom)\n",
    "        # if filtered correctly, only a single image remains\n",
    "        img: ee.Image = ee.Image(filtered_ic.first())  # have to cast here\n",
    "        img_name: str = sub(r\"\\.\\d+\", \"\", f\"z{zoom}/x{tx}/y{ty}/\") + name_suffix\n",
    "        # Export image\n",
    "        if sink == \"asset\":  # Replace with case / switch in python 3.10\n",
    "            task: Optional[ee.batch.Task] = tile_to_asset(\n",
    "                image=img,\n",
    "                tile=temp_tile,\n",
    "                export_scale=export_scale,\n",
    "                asset_path_prefix=asset_path,\n",
    "                asset_name=img_name.replace(\"/\", \"_\"),\n",
    "                overwrite=overwrite,\n",
    "                global_log_fields=global_log_fields\n",
    "            )\n",
    "            if task: task_list.append(task)\n",
    "        elif sink == \"cloud\":\n",
    "            if not bucket:\n",
    "                raise ArgumentError(\"Sink option requires \\\"bucket\\\" arg.\")\n",
    "            task: ee.batch.Task = tile_to_cloud_storage(\n",
    "                image=img,\n",
    "                tile=temp_tile,\n",
    "                export_scale=export_scale,\n",
    "                bucket=bucket,\n",
    "                bucket_path=img_name,\n",
    "                overwrite=overwrite,\n",
    "                global_log_fields=global_log_fields\n",
    "            )\n",
    "        else:\n",
    "            raise ArgumentError(\"unrecognized data sink: {sink}\")\n",
    "        task_list.append(task)\n",
    "    return task_list\n",
    "\n",
    "def export_tiles(\n",
    "    sink: str,\n",
    "    geometry: ee.Geometry,\n",
    "    zoom: int,\n",
    "    export_zoom: Optional[int] = None,\n",
    "    start: Optional[str] = None,\n",
    "    stop: Optional[str] = None,\n",
    "    step_months: int = 3,\n",
    "    window_years: int = 2,\n",
    "    overwrite: Optional[bool] = False,\n",
    "    bucket: Optional[str] = None,\n",
    "    asset_path: Optional[str] = None,\n",
    "    global_log_fields: Optional[Dict[str, str]] = None\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    From a geometry, creates tiles of input zoom level, calculates subtidal bathymetry in those\n",
    "    tiles, and exports those tiles.\n",
    "    args:\n",
    "        sink (str): type of data sink to export to. Viable options are: \"asset\" and \"cloud\".\n",
    "        geometry (ee.Geometry): geometry of the area of interest.\n",
    "        zoom (int): zoom level of the to-be-exported tiles.\n",
    "        export_zoom (int): zoom level for determining resolution of export tiles.\n",
    "        start (ee.String): start date in YYYY-MM-dd format, defaults to one timestep before stop.\n",
    "        stop (ee.String): stop date in YYYY-MM-dd format, defaults to start of this month\n",
    "        step_months (int): steps with which to roll the window over which the subtidal bathymetry\n",
    "            is calculated.\n",
    "        window_years (int): number of years over which the subtidal bathymetry is calculated.\n",
    "        overwrite (bool): whether to overwrite current tiles in the sink.\n",
    "        bucket (Optional(str)): bucket for sink \"cloud\".\n",
    "        asset_path (Optional(str)): Path where the asset will be stored. Only used when sink = \"asset\".\n",
    "        global_log_fields (Optional(Dict)): log fields for the entire cloud function.\n",
    "    \"\"\"\n",
    "    if not global_log_fields:\n",
    "        global_log_fields: Dict[str, str] = {}\n",
    "    \n",
    "    if not export_zoom:\n",
    "        export_zoom = zoom\n",
    "    \n",
    "    dates: List[Tuple[Date]] = get_rolling_window_dates(start, stop, step_months, window_years)\n",
    "    \n",
    "    # Get tiles\n",
    "    tiles: ee.FeatureCollection = tiler.get_tiles_for_geometry(geometry, ee.Number(zoom))\n",
    "\n",
    "    scale: float = tiler.zoom_to_scale(export_zoom).getInfo()\n",
    "    task_list: List[ee.batch.Task] = []\n",
    "    num_tiles: int = tiles.size().getInfo()\n",
    "    tile_list: ee.List = tiles.toList(num_tiles)\n",
    "\n",
    "    for date in dates:\n",
    "        sdb_tiles: ee.ImageCollection = tiles.map(\n",
    "            lambda tile: get_tile_bathymetry(\n",
    "                tile=tile,\n",
    "                start=ee.String(date[0]),\n",
    "                stop=ee.String(date[1])\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # Now export tiles\n",
    "        export_sdb_tiles(\n",
    "            sink=sink,\n",
    "            tile_list=tile_list,\n",
    "            num_tiles=num_tiles,\n",
    "            export_scale=scale,\n",
    "            sdb_tiles=sdb_tiles,\n",
    "            name_suffix=f\"t{date[0]}_{date[1]}\",\n",
    "            task_list=task_list,\n",
    "            overwrite=overwrite,\n",
    "            bucket=bucket,\n",
    "            asset_path=asset_path,\n",
    "            global_log_fields=global_log_fields\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
