{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThis code generates a fesibility area for deriving intertidal bathymetry. \\nIt computes the area between the the Lowest Astronomical Tide (LAT) and \\nthe Mean Seal Level + 10 m, based on a LAT map, and a Bathymetry and \\nelevation GEBCO map. \\n\\n    Author: Mario.FuentesMonjaraz@deltares.nl\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    \"\"\"\n",
    "    This code generates a fesibility area for deriving intertidal bathymetry. \n",
    "    It computes the area between the the Lowest Astronomical Tide (LAT) and \n",
    "    the Mean Seal Level + 10 m, based on a LAT map, and a Bathymetry and \n",
    "    elevation GEBCO map. \n",
    "\n",
    "        Author: Mario.FuentesMonjaraz@deltares.nl\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import dask\n",
    "import xarray as xr\n",
    "import pyproj\n",
    "import rioxarray\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import rasterio\n",
    "from rasterio.features import shapes\n",
    "from shapely.geometry import shape\n",
    "import re\n",
    "import glob\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to extract the coordinate part of the filename\n",
    "def extract_coordinates(filename):\n",
    "    match = re.search(r'gebco_2023_(n-?\\d+\\.\\d+_s-?\\d+\\.\\d+_w-?\\d+\\.\\d+_e-?\\d+\\.\\d+)', filename)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def assign_projection(ds, epsg=None):\n",
    "\n",
    "    if not epsg == None:\n",
    "        proj = pyproj.CRS.from_epsg(int(epsg))\n",
    "    else:\n",
    "        proj = pyproj.CRS.from_epsg(int(ds.crs.values.tolist()))\n",
    "\n",
    "    print(proj,\"projection was assigned to the dataset attributes\")\n",
    "    ds.attrs['crs'] = proj\n",
    "    return ds\n",
    "\n",
    "def print_ds_properties(rds,epsg=None):\n",
    "    # Print the grid size\n",
    "    print(\"Grid size:\", rds.rio.resolution())\n",
    "\n",
    "    #Print null data\n",
    "    print(\"no data:\", rds.rio.nodata)\n",
    "\n",
    "    # Print the projection information\n",
    "    if rds.rio.crs == None:\n",
    "        print(\"There is no projection\")\n",
    "        proj = pyproj.CRS.from_epsg(epsg)\n",
    "        rds.attrs['crs'] = proj\n",
    "        rds.rio.set_crs(proj, inplace=True)\n",
    "    else:\n",
    "        print(\"There is projection available\")\n",
    "    \n",
    "    print(\"Projection EPSG code is:\", rds.rio.crs, \"\\n\")\n",
    "    return\n",
    "\n",
    "def change_resolution(ds, new_resolution):\n",
    "    # Reproject the rioxarray object to the new resolution\n",
    "    reprojected_ds = ds.rio.reproject(ds.rio.crs, resolution=new_resolution, resampling=\"bilinear\")\n",
    "    return reprojected_ds\n",
    "\n",
    "def match_resolution(rds, rds_source):\n",
    "    # Reproject the rioxarray object to the new resolution\n",
    "    reprojected_ds = rds.rio.reproject(rds_source.rio.crs, resolution=rds_source.rio.resolution(), resampling= rioxarray.enums.Resampling.bilinear)\n",
    "    return reprojected_ds\n",
    "\n",
    "def redefine_null_for_nan(ds, new_null_value):\n",
    "    # Replace NaN values with the new null value\n",
    "    ds.values[np.isnan(ds.values)] = new_null_value\n",
    "    # ds.rio.update({'nodata': new_null_value})\n",
    "    return ds\n",
    "\n",
    "def create_gdf_from_geojson_files(input_aoi_data):\n",
    "    geojson_files = []\n",
    "\n",
    "    for filename in os.listdir(input_aoi_data):\n",
    "        if filename.endswith(\".geojson\"):\n",
    "            gdf = gpd.read_file(os.path.join(input_aoi_data,filename))\n",
    "            aoi_id = filename.split('_')\n",
    "            aoi_id = aoi_id[-1].split('.')[0]\n",
    "            gdf.insert(1, \"aoi\", aoi_id)\n",
    "            geojson_files.append((gdf))\n",
    "\n",
    "    aoi_gdf = gpd.GeoDataFrame(pd.concat(geojson_files, ignore_index=True)).drop(columns=[\"id\"])\n",
    "    return aoi_gdf\n",
    "\n",
    "def clip_raster(rds, geometry):\n",
    "    rds_clipped = rds.rio.clip(geometry)\n",
    "    return rds_clipped\n",
    "\n",
    "def clip_raster_with_gdf(rds, gdf):\n",
    "    rds_clipped_list = []\n",
    "    for index, row in gdf.iterrows():\n",
    "        aoi = row[\"aoi\"]\n",
    "        try:\n",
    "            geometry = gdf.iloc[index:index+1].geometry\n",
    "            rds_clipped = rds.rio.clip(geometry)\n",
    "            rds_clipped_list.append(rds_clipped)\n",
    "            print(f\"Successful processing row {index} {aoi}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing row {index} {aoi}: {e}\")\n",
    "            rds_clipped_list.append(\"NaN\")\n",
    "            continue\n",
    "    print(\"\\n\")\n",
    "    return rds_clipped_list \n",
    "\n",
    "def apply_lat_mask_1(depth, lat):\n",
    "\n",
    "    binary_mask = lat > depth\n",
    "    depth_lat = depth.where(~binary_mask, other=np.nan)\n",
    "    return depth_lat \n",
    "\n",
    "def apply_lat_mask_2(depth, lat):\n",
    "\n",
    "    binary_mask = lat <= depth\n",
    "    depth_lat = depth.where(~binary_mask, other=np.nan)\n",
    "    return depth_lat \n",
    "\n",
    "def apply_hat_mask_1(depth_lat, hat_rds):\n",
    "\n",
    "    binary_mask =  depth_lat > hat_rds \n",
    "    depth_lat_hat = depth_lat.where(~binary_mask, other=np.nan)\n",
    "    return depth_lat_hat\n",
    "\n",
    "def apply_hat_mask_2(depth_lat, hat_rds):\n",
    "\n",
    "    binary_mask =  depth_lat <= hat_rds \n",
    "    depth_lat_hat = depth_lat.where(~binary_mask, other=np.nan)\n",
    "    return depth_lat_hat\n",
    "\n",
    "def get_coastline(lw_rds, cathegory):\n",
    "    mask = cathegory\n",
    "    masked_data = lw_rds.where(mask, other=np.nan)\n",
    "    return masked_data\n",
    "\n",
    "def save_mask(depth_lat_hat, name):\n",
    "    # Assign null values to the created mask\n",
    "    depth_lat_hat_clean = xr.where((depth_lat_hat.isnull()) | (depth_lat_hat == 9999.0), np.nan, depth_lat_hat)\n",
    "    depth_lat_hat_ones  = xr.where(depth_lat_hat_clean.isnull(), np.nan, depth_lat_hat_clean / depth_lat_hat_clean)\n",
    "\n",
    "    # depth_lat.rio.to_raster(os.path.join(output_data_path,f\"gebco_2023_{coordinates}_depth_lat.tif\"), crs=f\"EPSG:{4326}\")\n",
    "    depth_lat_hat.rio.to_raster(os.path.join(output_data_path,f\"gebco_2023_{coordinates}_depth_{name}.tif\"), crs=f\"EPSG:{4326}\")\n",
    "    depth_lat_hat_ones.rio.to_raster(os.path.join(output_data_path, f\"gebco_2023_{coordinates}_depth_{name}_ones.tif\"), crs=f\"EPSG:{4326}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define packages paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data path already exists: d:\\Proyectos2024\\Copernicus\\Repository\\Copernicus\\Repository\\eo-bathymetry\\notebooks\\Outputv3\n"
     ]
    }
   ],
   "source": [
    "repository_path = os.path.dirname(os.getcwd())\n",
    "input_data_path = r\"D:\\Proyectos2024\\Copernicus\\Repository\\Copernicus\\Data\" #This folder has to exist with alll the LAT and HAT data that can be downloaded here https://nx1512.your-storageshare.de/s/Xzc6BgHCZ37KbZz\n",
    "input_aoi_data = r\"p:\\11209821-cmems-global-sdb\\00_miscellaneous\\AOIs\"\n",
    "output_data_path = os.path.join(repository_path,\"Outputv3\")\n",
    "\n",
    "if not os.path.exists(output_data_path):\n",
    "    print(\"Output data path does not exist. Creating directory...\")\n",
    "    os.makedirs(output_data_path)\n",
    "    print(\"Output data path created:\", output_data_path)\n",
    "else:\n",
    "    print(\"Input data path already exists:\", output_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get HAT and LAT files\n",
    "file_paths = glob.glob(os.path.join(input_data_path, 'gebco_2023*.nc'))\n",
    "filenames = [os.path.basename(document) for document in file_paths]\n",
    "\n",
    "# Get area of coverage of each gebco file\n",
    "coordinates_list = [extract_coordinates(filename) for filename in filenames]\n",
    "coordinates_list = set(coordinates_list)\n",
    "coordinates_list = list(coordinates_list)\n",
    "\n",
    "# Reduce the datasets for testing\n",
    "coordinates_list = ['n90.0_s0.0_w90.0_e180.0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get HAT and LAT files\n",
    "file_paths = glob.glob(os.path.join(input_data_path, 'gebco_2023*.nc'))\n",
    "filenames = [os.path.basename(document) for document in file_paths]\n",
    "\n",
    "# Get area of coverage of each gebco file\n",
    "coordinates_list = [extract_coordinates(filename) for filename in filenames]\n",
    "coordinates_list = set(coordinates_list)\n",
    "coordinates_list = list(coordinates_list)\n",
    "\n",
    "# Reduce the datasets for testing\n",
    "coordinates_list = ['n90.0_s0.0_w90.0_e180.0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gebco_2023_n90.0_s0.0_w90.0_e180.0_depthmsl.nc\n",
      "Grid size: (0.004166666666666668, -0.004166666666666667)\n",
      "no data: 9999.0\n",
      "There is projection available\n",
      "Projection EPSG code is: EPSG:4326 \n",
      "\n",
      "gebco_2023_n90.0_s0.0_w90.0_e180.0_lat.nc\n",
      "Grid size: (0.004166666666666668, -0.004166666666666667)\n",
      "no data: 9999.0\n",
      "There is projection available\n",
      "Projection EPSG code is: EPSG:4326 \n",
      "\n",
      "gebco_2023_n90.0_s0.0_w90.0_e180.0_hat.nc\n",
      "Grid size: (0.004166666666666668, -0.004166666666666667)\n",
      "no data: 9999.0\n",
      "There is projection available\n",
      "Projection EPSG code is: EPSG:4326 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for coordinates in coordinates_list:\n",
    "\n",
    "    # Read gebco, lat, and hat files\n",
    "    depthmsl_rds = rioxarray.open_rasterio(os.path.join(input_data_path,f'gebco_2023_{coordinates}_depthmsl.nc'), chunks={'y': 100, 'x':100})\n",
    "\n",
    "    lat_rds = rioxarray.open_rasterio(os.path.join(input_data_path,f'gebco_2023_{coordinates}_lat.nc'), chunks={'y': 100, 'x':100})\n",
    "\n",
    "    hat_rds = rioxarray.open_rasterio(os.path.join(input_data_path,f'gebco_2023_{coordinates}_hat.nc'), chunks={'y': 100, 'x':100})\n",
    "\n",
    "    lw_rds = rioxarray.open_rasterio(os.path.join(input_data_path,f'LandWater15ARC_rusia.tif'))\n",
    "\n",
    "    print(f'gebco_2023_{coordinates}_depthmsl.nc')\n",
    "    print_ds_properties(depthmsl_rds)\n",
    "    print(f'gebco_2023_{coordinates}_lat.nc')\n",
    "    print_ds_properties(lat_rds)\n",
    "    print(f'gebco_2023_{coordinates}_hat.nc')\n",
    "    print_ds_properties(hat_rds)\n",
    "\n",
    "    # # Remove values below below lat and over hat \n",
    "    # depth_lat_1  = apply_lat_mask_1(depthmsl_rds, lat_rds)\n",
    "    # depth_lat_2 = apply_lat_mask_2(depthmsl_rds, lat_rds)\n",
    "    # depth_hat_1 = apply_hat_mask_1(depthmsl_rds, hat_rds)\n",
    "    # depth_hat_2 = apply_hat_mask_2(depthmsl_rds, hat_rds)\n",
    "\n",
    "    # save_mask(depth_lat_1, 'lat_1')\n",
    "    # save_mask(depth_lat_2, 'lat_2')\n",
    "    # save_mask(depth_hat_1, 'hat_1')\n",
    "    # save_mask(depth_hat_2, 'hat_2')\n",
    "\n",
    "lat_1 = rioxarray.open_rasterio(os.path.join(output_data_path, f\"gebco_2023_{coordinates}_depth_lat_1_ones.tif\"))\n",
    "lat_2 = rioxarray.open_rasterio(os.path.join(output_data_path, f\"gebco_2023_{coordinates}_depth_lat_1_ones.tif\"))\n",
    "hat_1 = rioxarray.open_rasterio(os.path.join(output_data_path, f\"gebco_2023_{coordinates}_depth_hat_1_ones.tif\"))\n",
    "hat_2 = rioxarray.open_rasterio(os.path.join(output_data_path, f\"gebco_2023_{coordinates}_depth_hat_2_ones.tif\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "coastline_mask = lw_rds.where(lw_rds == 2.0, other=0)\n",
    "hat_2_mask     = hat_2.where(hat_2 == 1.0, other=0)\n",
    "hat_2_mask.rio.to_raster(os.path.join(output_data_path,f\"hat_2_mask_v100.tif\"), crs=f\"EPSG:{4326}\")\n",
    "coastline_mask.rio.to_raster(os.path.join(output_data_path,f\"coastline_mask_v100.tif\"), crs=f\"EPSG:{4326}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "hat_2_mask = rioxarray.open_rasterio(os.path.join(output_data_path,f\"hat_2_mask_v100.tif\"))\n",
    "coastline_mask = rioxarray.open_rasterio(os.path.join(output_data_path,f\"coastline_mask_v100.tif\"))\n",
    "\n",
    "hat_2_mask.rio.write_crs('EPSG:4326', inplace=True)\n",
    "coastline_mask.rio.write_crs('EPSG:4326', inplace=True)\n",
    "\n",
    "hat_2_mask, coastline_mask = xr.align(hat_2_mask, coastline_mask)\n",
    "\n",
    "addition = hat_2_mask + coastline_mask\n",
    "\n",
    "addition_nan = addition.where(addition != 0, np.nan)\n",
    "addition_nan.rio.write_crs('EPSG:4326', inplace=True)\n",
    "\n",
    "addition_nan.rio.to_raster(os.path.join(output_data_path,f\"addition_v5000.tif\"), crs=f\"EPSG:{4326}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[79], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m structure \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mones((\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m3\u001b[39m), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mbool\u001b[39m)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Dilate the second layer\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m dilated_layer2 \u001b[38;5;241m=\u001b[39m \u001b[43mbinary_dilation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlayer2_np\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstructure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstructure\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Find the touching pixels in the first layer\u001b[39;00m\n\u001b[0;32m     16\u001b[0m touching_pixels \u001b[38;5;241m=\u001b[39m (layer1_np \u001b[38;5;241m&\u001b[39m dilated_layer2)\n",
      "File \u001b[1;32mc:\\Users\\fuentesm\\AppData\\Local\\anaconda3\\envs\\copernicus\\Lib\\site-packages\\scipy\\ndimage\\_morphology.py:517\u001b[0m, in \u001b[0;36mbinary_dilation\u001b[1;34m(input, structure, iterations, mask, output, border_value, origin, brute_force)\u001b[0m\n\u001b[0;32m    515\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ii \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(origin)):\n\u001b[0;32m    516\u001b[0m     origin[ii] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39morigin[ii]\n\u001b[1;32m--> 517\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mstructure\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[43mii\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m&\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    518\u001b[0m         origin[ii] \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    520\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _binary_erosion(\u001b[38;5;28minput\u001b[39m, structure, iterations, mask,\n\u001b[0;32m    521\u001b[0m                        output, border_value, origin, \u001b[38;5;241m1\u001b[39m, brute_force)\n",
      "\u001b[1;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "from scipy.ndimage import binary_dilation\n",
    "\n",
    "# Convert DataArrays to NumPy arrays\n",
    "layer1_np = lat_2.data\n",
    "layer2_np = addition_nan.data\n",
    "\n",
    "# Define the structuring element (8-connectivity)\n",
    "structure = np.ones((3, 3), dtype=bool)\n",
    "\n",
    "# Dilate the second layer\n",
    "dilated_layer2 = binary_dilation(layer2_np, structure=structure)\n",
    "\n",
    "# Find the touching pixels in the first layer\n",
    "touching_pixels = (layer1_np & dilated_layer2)\n",
    "\n",
    "# Convert the result back to a DataArray\n",
    "touching_pixels_da = xr.DataArray(touching_pixels, dims=layer1_np.dims, coords=layer1_np.coords)\n",
    "\n",
    "print(touching_pixels_da)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gebco_2023_n90.0_s0.0_w90.0_e180.0_depthmsl.nc\n",
      "Grid size: (0.004166666666666668, -0.004166666666666667)\n",
      "no data: 9999.0\n",
      "There is projection available\n",
      "Projection EPSG code is: EPSG:4326 \n",
      "\n",
      "gebco_2023_n90.0_s0.0_w90.0_e180.0_lat.nc\n",
      "Grid size: (0.004166666666666668, -0.004166666666666667)\n",
      "no data: 9999.0\n",
      "There is projection available\n",
      "Projection EPSG code is: EPSG:4326 \n",
      "\n",
      "gebco_2023_n90.0_s0.0_w90.0_e180.0_hat.nc\n",
      "Grid size: (0.004166666666666668, -0.004166666666666667)\n",
      "no data: 9999.0\n",
      "There is projection available\n",
      "Projection EPSG code is: EPSG:4326 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for coordinates in coordinates_list:\n",
    "\n",
    "    # Read gebco, lat, and hat files\n",
    "    depthmsl_ds = xr.open_dataset(os.path.join(input_data_path, f'gebco_2023_{coordinates}_depthmsl.nc'), chunks={'lat': 100, 'lon':100})\n",
    "    depthmsl_rds = rds = rioxarray.open_rasterio(os.path.join(input_data_path,f'gebco_2023_{coordinates}_depthmsl.nc'), chunks={'y': 100, 'x':100})\n",
    "\n",
    "    lat_ds = xr.open_dataset(os.path.join(input_data_path,f'gebco_2023_{coordinates}_lat.nc'), chunks={'lat': 100, 'lon':100})\n",
    "    lat_rds = rioxarray.open_rasterio(os.path.join(input_data_path,f'gebco_2023_{coordinates}_lat.nc'), chunks={'y': 100, 'x':100})\n",
    "\n",
    "    hat_ds = xr.open_dataset(os.path.join(input_data_path,f'gebco_2023_{coordinates}_hat.nc'), chunks={'lat': 100, 'lon':100})\n",
    "    hat_rds = rioxarray.open_rasterio(os.path.join(input_data_path,f'gebco_2023_{coordinates}_hat.nc'), chunks={'y': 100, 'x':100})\n",
    "\n",
    "    # Set null values in the datasets\n",
    "    # depthmsl_rds = depthmsl_rds.rio.set_nodata(np.nan)\n",
    "    # lat_rds      = lat_rds.rio.set_nodata(np.nan)\n",
    "    # hat_rds      = hat_rds.rio.set_nodata(np.nan)\n",
    "\n",
    "    print(f'gebco_2023_{coordinates}_depthmsl.nc')\n",
    "    print_ds_properties(depthmsl_rds)\n",
    "    print(f'gebco_2023_{coordinates}_lat.nc')\n",
    "    print_ds_properties(lat_rds)\n",
    "    print(f'gebco_2023_{coordinates}_hat.nc')\n",
    "    print_ds_properties(hat_rds)\n",
    "\n",
    "    # Remove values below below lat and over hat \n",
    "    # depth_lat     = apply_lat_mask(depthmsl_rds, lat_rds)\n",
    "    # depth_lat_hat = apply_hat_mask(depth_lat, hat_rds)\n",
    "\n",
    "    # depth_lat     = apply_lat_mask(depthmsl_rds, lat_rds)\n",
    "    depth_lat_hat = apply_hat_mask(depthmsl_rds, hat_rds)\n",
    "\n",
    "    # Assign null values to the created mask\n",
    "    depth_lat_hat_clean = xr.where((depth_lat_hat.isnull()) | (depth_lat_hat == 9999.0), np.nan, depth_lat_hat)\n",
    "    depth_lat_hat_ones  = xr.where(depth_lat_hat_clean.isnull(), np.nan, depth_lat_hat_clean / depth_lat_hat_clean)\n",
    "\n",
    "    # depth_lat.rio.to_raster(os.path.join(output_data_path,f\"gebco_2023_{coordinates}_depth_lat.tif\"), crs=f\"EPSG:{4326}\")\n",
    "    depth_lat_hat.rio.to_raster(os.path.join(output_data_path,f\"gebco_2023_{coordinates}_depth_lat_hat.tif\"), crs=f\"EPSG:{4326}\")\n",
    "    depth_lat_hat_ones.rio.to_raster(os.path.join(output_data_path, f\"gebco_2023_{coordinates}_depth_lat_hat_ones.tif\"), crs=f\"EPSG:{4326}\")\n",
    "\n",
    "    # # Open raster file using rasterio\n",
    "    # with rasterio.open(os.path.join(output_data_path,f\"gebco_2023_{coordinates}_depth_lat_hat_ones.tif\")) as src:\n",
    "    #     # Read raster data into numpy array\n",
    "    #     raster_array = src.read(1)  # Assuming it's a single band raster, adjust if necessary\n",
    "    #     # Extract transformation metadata\n",
    "    #     transform = src.transform\n",
    "    #     # Polygonize raster data\n",
    "    #     polygons = list(shapes(raster_array, mask=None, transform=transform))\n",
    "    #     # Convert polygons to Shapely geometries and record pixel values\n",
    "    #     geometries_with_values = [(shape(polygon), value) for polygon, value in polygons]\n",
    "\n",
    "    # # Extract geometries and values into separate lists\n",
    "    # geometries = [geometry for geometry, value in geometries_with_values]\n",
    "    # values = [value for geometry, value in geometries_with_values]\n",
    "\n",
    "    # # Convert Shapely geometries and pixel values to GeoDataFrame\n",
    "    # geo_df = gpd.GeoDataFrame(geometry=geometries, data={'pixel_value': values})\n",
    "\n",
    "    # geo_df = geo_df[~np.isnan(geo_df['pixel_value'])]\n",
    "    # geo_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    # # Define the EPSG code for the desired projection\n",
    "    # epsg_code = 4326  # For example, EPSG code for WGS 84\n",
    "\n",
    "    # # Assign the projection to the GeoDataFrame\n",
    "    # geo_df.crs = f\"EPSG:{epsg_code}\"\n",
    "\n",
    "    # # Save GeoDataFrame to file\n",
    "    # # geo_df.to_file(os.path.join(output_data_path,f\"gebco_2023_{coordinates}_depth_lat_hat.shp\"))\n",
    "    # geo_df.to_file(os.path.join(output_data_path,f\"gebco_2023_{coordinates}_depth_lat_hat.geojson\"), driver=\"GeoJSON\", crs=f\"EPSG:{epsg_code}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "copernicus",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
